{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa944b1-7866-44bb-8c9c-d6a9055ad63c",
   "metadata": {},
   "source": [
    "# 1. Heart Attack Prediction (60pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d872e0cb-cfd6-4276-92f2-c227a15820b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec74656-5548-4c21-930c-ceaaa89a334f",
   "metadata": {},
   "source": [
    "## 1. (2pt) Load the data and drop the variable slp, oldpeak and thall, since they do not have descriptions available. Do some basic sanity check (descriptive statistics; missing values; data types...). The data should contain 303 rows, and 11 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9a1f45-68be-456f-a76e-04ebd51fe42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = pd.read_csv(\"../data/heart.csv\")\n",
    "heart = heart.drop([\"slp\",\"oldpeak\",\"thall\"], axis=1)\n",
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b286d33-dfb9-45e9-9dd9-40edad380c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>caa</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  caa  output\n",
       "0     63    1   3     145   233    1        0       150     0    0       1\n",
       "1     37    1   2     130   250    0        1       187     0    0       1\n",
       "2     41    0   1     130   204    0        0       172     0    0       1\n",
       "3     56    1   1     120   236    0        1       178     0    0       1\n",
       "4     57    0   0     120   354    0        1       163     1    0       1\n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...  ...     ...\n",
       "298   57    0   0     140   241    0        1       123     1    0       0\n",
       "299   45    1   3     110   264    0        1       132     0    0       0\n",
       "300   68    1   0     144   193    1        1       141     0    2       0\n",
       "301   57    1   0     130   131    0        1       115     1    1       0\n",
       "302   57    0   1     130   236    0        0       174     0    1       0\n",
       "\n",
       "[303 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e872c966-fb42-4a6b-8dce-f90c39a31596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trtbps      0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalachh    0\n",
       "exng        0\n",
       "caa         0\n",
       "output      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e40f362-4722-4310-944d-1f33e7e4e64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         int64\n",
       "sex         int64\n",
       "cp          int64\n",
       "trtbps      int64\n",
       "chol        int64\n",
       "fbs         int64\n",
       "restecg     int64\n",
       "thalachh    int64\n",
       "exng        int64\n",
       "caa         int64\n",
       "output      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d9c3f8-df28-47bd-a0b9-c22c8a31ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart['cp'] = pd.Categorical(heart.cp)\n",
    "heart['caa'] = pd.Categorical(heart.caa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858192b5-e4e0-4942-a45e-91c5eab4e15a",
   "metadata": {},
   "source": [
    "## 2. (22pt) Construct a simple logistic regression with statsmodel.formula.api package. The outcome variable is output. The rest 10 variables (age, sex, cp, trtbps, chol, fbs, restecg, thalachh, exng, caa) in the dataset are predictors. Print out the marginal effect summary table and answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4950e550-d298-49d2-a173-df185f52c572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.356701\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>output</td>      <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   287</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 04 Mar 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.4824</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>01:02:10</td>     <th>  Log-Likelihood:    </th> <td> -108.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -208.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.064e-34</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    0.4078</td> <td>    2.464</td> <td>    0.166</td> <td> 0.869</td> <td>   -4.421</td> <td>    5.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.1]</th>   <td>    1.5510</td> <td>    0.543</td> <td>    2.857</td> <td> 0.004</td> <td>    0.487</td> <td>    2.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.2]</th>   <td>    1.7048</td> <td>    0.441</td> <td>    3.865</td> <td> 0.000</td> <td>    0.840</td> <td>    2.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.3]</th>   <td>    1.8943</td> <td>    0.666</td> <td>    2.843</td> <td> 0.004</td> <td>    0.589</td> <td>    3.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.1]</th>  <td>   -1.8878</td> <td>    0.457</td> <td>   -4.134</td> <td> 0.000</td> <td>   -2.783</td> <td>   -0.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.2]</th>  <td>   -3.0263</td> <td>    0.645</td> <td>   -4.690</td> <td> 0.000</td> <td>   -4.291</td> <td>   -1.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.3]</th>  <td>   -2.4131</td> <td>    0.779</td> <td>   -3.098</td> <td> 0.002</td> <td>   -3.940</td> <td>   -0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.4]</th>  <td>    0.4632</td> <td>    1.569</td> <td>    0.295</td> <td> 0.768</td> <td>   -2.613</td> <td>    3.539</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>       <td>    0.0239</td> <td>    0.024</td> <td>    0.999</td> <td> 0.318</td> <td>   -0.023</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>       <td>   -2.1000</td> <td>    0.452</td> <td>   -4.648</td> <td> 0.000</td> <td>   -2.985</td> <td>   -1.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trtbps</th>    <td>   -0.0292</td> <td>    0.011</td> <td>   -2.755</td> <td> 0.006</td> <td>   -0.050</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>      <td>   -0.0062</td> <td>    0.004</td> <td>   -1.565</td> <td> 0.118</td> <td>   -0.014</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>       <td>    0.4568</td> <td>    0.502</td> <td>    0.910</td> <td> 0.363</td> <td>   -0.527</td> <td>    1.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg</th>   <td>    0.3251</td> <td>    0.340</td> <td>    0.955</td> <td> 0.340</td> <td>   -0.342</td> <td>    0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalachh</th>  <td>    0.0365</td> <td>    0.011</td> <td>    3.471</td> <td> 0.001</td> <td>    0.016</td> <td>    0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exng</th>      <td>   -1.1710</td> <td>    0.418</td> <td>   -2.803</td> <td> 0.005</td> <td>   -1.990</td> <td>   -0.352</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                 output   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      287\n",
       "Method:                           MLE   Df Model:                           15\n",
       "Date:                Fri, 04 Mar 2022   Pseudo R-squ.:                  0.4824\n",
       "Time:                        01:02:10   Log-Likelihood:                -108.08\n",
       "converged:                       True   LL-Null:                       -208.82\n",
       "Covariance Type:            nonrobust   LLR p-value:                 1.064e-34\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.4078      2.464      0.166      0.869      -4.421       5.237\n",
       "cp[T.1]        1.5510      0.543      2.857      0.004       0.487       2.615\n",
       "cp[T.2]        1.7048      0.441      3.865      0.000       0.840       2.569\n",
       "cp[T.3]        1.8943      0.666      2.843      0.004       0.589       3.200\n",
       "caa[T.1]      -1.8878      0.457     -4.134      0.000      -2.783      -0.993\n",
       "caa[T.2]      -3.0263      0.645     -4.690      0.000      -4.291      -1.762\n",
       "caa[T.3]      -2.4131      0.779     -3.098      0.002      -3.940      -0.887\n",
       "caa[T.4]       0.4632      1.569      0.295      0.768      -2.613       3.539\n",
       "age            0.0239      0.024      0.999      0.318      -0.023       0.071\n",
       "sex           -2.1000      0.452     -4.648      0.000      -2.985      -1.214\n",
       "trtbps        -0.0292      0.011     -2.755      0.006      -0.050      -0.008\n",
       "chol          -0.0062      0.004     -1.565      0.118      -0.014       0.002\n",
       "fbs            0.4568      0.502      0.910      0.363      -0.527       1.440\n",
       "restecg        0.3251      0.340      0.955      0.340      -0.342       0.992\n",
       "thalachh       0.0365      0.011      3.471      0.001       0.016       0.057\n",
       "exng          -1.1710      0.418     -2.803      0.005      -1.990      -0.352\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "m = smf.logit('output ~ age + sex + cp + trtbps + chol + fbs + restecg + thalachh + exng + caa', data=heart).fit()\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdde1aee-3241-4f73-af4c-8b12fc4c0636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>output</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>         <td>dydx</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>            <td>overall</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <th></th>        <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.1]</th>  <td>    0.1742</td> <td>    0.058</td> <td>    3.010</td> <td> 0.003</td> <td>    0.061</td> <td>    0.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.2]</th>  <td>    0.1915</td> <td>    0.045</td> <td>    4.270</td> <td> 0.000</td> <td>    0.104</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cp[T.3]</th>  <td>    0.2128</td> <td>    0.071</td> <td>    2.987</td> <td> 0.003</td> <td>    0.073</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.1]</th> <td>   -0.2121</td> <td>    0.046</td> <td>   -4.648</td> <td> 0.000</td> <td>   -0.301</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.2]</th> <td>   -0.3400</td> <td>    0.062</td> <td>   -5.477</td> <td> 0.000</td> <td>   -0.462</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.3]</th> <td>   -0.2711</td> <td>    0.082</td> <td>   -3.322</td> <td> 0.001</td> <td>   -0.431</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>caa[T.4]</th> <td>    0.0520</td> <td>    0.176</td> <td>    0.295</td> <td> 0.768</td> <td>   -0.294</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>      <td>    0.0027</td> <td>    0.003</td> <td>    1.006</td> <td> 0.314</td> <td>   -0.003</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex</th>      <td>   -0.2359</td> <td>    0.045</td> <td>   -5.291</td> <td> 0.000</td> <td>   -0.323</td> <td>   -0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>trtbps</th>   <td>   -0.0033</td> <td>    0.001</td> <td>   -2.891</td> <td> 0.004</td> <td>   -0.006</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chol</th>     <td>   -0.0007</td> <td>    0.000</td> <td>   -1.582</td> <td> 0.114</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fbs</th>      <td>    0.0513</td> <td>    0.056</td> <td>    0.914</td> <td> 0.361</td> <td>   -0.059</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>restecg</th>  <td>    0.0365</td> <td>    0.038</td> <td>    0.959</td> <td> 0.338</td> <td>   -0.038</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thalachh</th> <td>    0.0041</td> <td>    0.001</td> <td>    3.730</td> <td> 0.000</td> <td>    0.002</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>exng</th>     <td>   -0.1315</td> <td>    0.045</td> <td>   -2.938</td> <td> 0.003</td> <td>   -0.219</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:                 output\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "==============================================================================\n",
       "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "cp[T.1]        0.1742      0.058      3.010      0.003       0.061       0.288\n",
       "cp[T.2]        0.1915      0.045      4.270      0.000       0.104       0.279\n",
       "cp[T.3]        0.2128      0.071      2.987      0.003       0.073       0.352\n",
       "caa[T.1]      -0.2121      0.046     -4.648      0.000      -0.301      -0.123\n",
       "caa[T.2]      -0.3400      0.062     -5.477      0.000      -0.462      -0.218\n",
       "caa[T.3]      -0.2711      0.082     -3.322      0.001      -0.431      -0.111\n",
       "caa[T.4]       0.0520      0.176      0.295      0.768      -0.294       0.398\n",
       "age            0.0027      0.003      1.006      0.314      -0.003       0.008\n",
       "sex           -0.2359      0.045     -5.291      0.000      -0.323      -0.149\n",
       "trtbps        -0.0033      0.001     -2.891      0.004      -0.006      -0.001\n",
       "chol          -0.0007      0.000     -1.582      0.114      -0.002       0.000\n",
       "fbs            0.0513      0.056      0.914      0.361      -0.059       0.161\n",
       "restecg        0.0365      0.038      0.959      0.338      -0.038       0.111\n",
       "thalachh       0.0041      0.001      3.730      0.000       0.002       0.006\n",
       "exng          -0.1315      0.045     -2.938      0.003      -0.219      -0.044\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f4ac5-6415-41fd-b8fc-9ed4cb3f30ec",
   "metadata": {},
   "source": [
    "* (6pt) Interpret coefficient for sex. Is it statistically significant at significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926de03-4d39-4b07-a303-73beb5e579ae",
   "metadata": {},
   "source": [
    "Yes, it is statistically significant. $H0$ is outside the confidence interval, the p-value is less than the significance level of 0.05, and the z-value seems relatively high. All of these makes it statistically significant. Using **get_margeff()** to get the marginal effects, we get the following interpretation: Males are about 23.59% points less likely to get a heart attack, if other characteristics stays the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271738e5-2592-43ec-824f-b78d7b84a1b9",
   "metadata": {},
   "source": [
    "* (6pt) Interpret coefficient for cp. Is it statistically significant at significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f89d2-f3b9-4dd8-a4c4-f3cc410003c6",
   "metadata": {},
   "source": [
    "cp is also statistically significant because $H0$ does not fall inbetween the confidence interval, the p-value is less than the significant level, and the z-value is relatively high. Because cp is a categorical variable, each category has its own interpretation:\n",
    "* cp[T.0]: Reference category\n",
    "* cp[T.1]: People with atypical angina are 17.42% points more likely to get a heart attack than those with typical angina, given that all other coeffecients stays the same\n",
    "* cp[T.2]: People with non-anginal pain are 19.15% points more likely to get a heart attack than those with typical angina, given that all other coefficients stays the same\n",
    "* cp[T.3]: People that are asymptomatic are 21.28% points more likely to get a heart attack than those with typical angina, given that all other coefficients stays the same\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddda4c2-1240-4a6c-a0be-a08090ec108c",
   "metadata": {},
   "source": [
    "* (6pt) Interpret the coefficient for age. Is it statistically significant at significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ffe7c-231d-44d0-a4e3-19cbc3041886",
   "metadata": {},
   "source": [
    "Age is not statistically significant because $H0$ is between the confidence interval, the p-value is above the significance level of 0.05, and the z-value is low. Age can be interpreted as the following: 1 year older means there is a .08% points decrease in the chance of getting a heart attack, given that all other characteristics stays equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c4f6f9-50b6-4563-a5fa-bc32e76c6489",
   "metadata": {},
   "source": [
    "* (4pt) What are the variables that are associated with lower chance of having a heart attack, and also are statistically significant? Do they intuitively make sense? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91200f6e-f92b-4e69-9177-10deb3a1d62e",
   "metadata": {},
   "source": [
    "The variables that are associated with having a lower chance of getting a heart attack are:\n",
    "* sex - male/female\n",
    "* trtbps - resting blood pressure\n",
    "* chol - cholestoral\n",
    "* exng - exercise induced angina\n",
    "* caa - number of major vessels\n",
    "These numbers do not make sense. From my knowledge, males are more likely to get a heart attack than females. Also, people with high cholestoral are at greater risk to get a heart attack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f80194-d2f7-4682-8ce5-08c5e144ed82",
   "metadata": {},
   "source": [
    "## 3. (6pt) Now let’s construct the same model with sklearn package using the following code: LogisticRegression(penalty=’none’, solver=’newton-cg’).fit(X,y). Remember that sklearn package requires the predictor values (X) to be separated with the outcome variable (y). The predictor values also need to be in matrix format. Answer the following question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e803dc-d30c-4049-a599-9fff9e903a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = heart.drop([\"output\"], axis=1)\n",
    "y = heart[\"output\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a14369-7add-4a98-b52c-10bc4852e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_dummies = pd.get_dummies(x, drop_first=True, columns=[\"cp\", \"caa\"])\n",
    "m = LogisticRegression(penalty=\"none\",solver=\"newton-cg\").fit(x_dummies, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d51c5-1b07-48b7-a4df-65aedeab98d8",
   "metadata": {},
   "source": [
    "* (6pt) Print out the coefficient and intercept. Did you get the same intercept and coefficients as what you got from statsmodel.formula.api package? (you are supposed to!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e6aeb6-0cac-4c38-a0f8-357bd83da806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  [0.40774509]\n",
      "Coefficients:  [[ 0.02385761 -2.09999102 -0.02920269 -0.00616402  0.4567869   0.3251173\n",
      "   0.03647469 -1.17101514  1.5510426   1.70481698  1.8943255  -1.88776461\n",
      "  -3.02631323 -2.41307618  0.46326514]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept: \", m.intercept_)\n",
    "print(\"Coefficients: \", m.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bd34e-7f8e-4a98-937c-71ca5fcc0989",
   "metadata": {},
   "source": [
    "Yes, the intercepts and coefficients are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de991b73-7ef8-4596-8998-cd76796048a9",
   "metadata": {},
   "source": [
    "## 4. (18pt) With the sklearn model, let’s do some predictions on the training set (the same X and y we used to train the model from Q3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7fcc96-48cd-4644-854c-e3290d2cd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b09a25d-f0a6-41da-b3a3-d0762d1aac3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.35438582]),\n",
       " array([[-0.02749316, -1.97838742,  0.9064679 , -0.02243834, -0.00677369,\n",
       "          0.26884218,  0.73431038,  0.03937371, -0.92981693, -0.76184321]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(penalty='none',solver='newton-cg').fit(train_X, train_y)\n",
    "logistic.intercept_, logistic.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a1f636-e2d8-4a8e-8ebf-d354d7c13749",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred_prob = logistic.predict_proba(test_X) #predict probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538d230-913b-43e7-844a-e373dbc70a65",
   "metadata": {},
   "source": [
    "* (6pt) The probability of having a heart attack: P (output=1|X). Print out the first 10 probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b0440a5-8f1b-4872-873c-00ae95521534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22862983, 0.77137017],\n",
       "       [0.08965974, 0.91034026],\n",
       "       [0.06888269, 0.93111731],\n",
       "       [0.33964775, 0.66035225],\n",
       "       [0.03192148, 0.96807852],\n",
       "       [0.774059  , 0.225941  ],\n",
       "       [0.0537829 , 0.9462171 ],\n",
       "       [0.32152002, 0.67847998],\n",
       "       [0.68997557, 0.31002443],\n",
       "       [0.48318524, 0.51681476]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "504ec4c6-30c9-4b9e-a30c-7116d2878662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77137017, 0.91034026, 0.93111731, 0.66035225, 0.96807852,\n",
       "       0.225941  , 0.9462171 , 0.67847998, 0.31002443, 0.51681476])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_pred_prob_1 = test_y_pred_prob[:,1]\n",
    "test_y_pred_prob_1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4289f44-ede0-4437-8aff-6f773b6af372",
   "metadata": {},
   "source": [
    "* (6pt) The outcome labels — that is, we directly predict whether or not the person will have a heart attack, instead of predicting the probability. Print out the first 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04671678-5a28-45cb-b8a5-f1b6f2c8e93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_pred_labels = logistic.predict(test_X)\n",
    "test_y_pred_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9575a2d-1500-460e-a8c3-8985b0f7df23",
   "metadata": {},
   "source": [
    "* (6pt) Show the steps of how to convert from probabilities to the labels using threshold 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a06d58f-e39d-41f1-9c79-73bf3e4d83ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "## compare probabilities of y=1 with the threshold:\n",
    "## - if probability > threshold, predict y=1\n",
    "## - if probability <= threshold, predict y=0\n",
    "1.0*(test_y_pred_prob_1>threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8437f3-0d25-4597-a204-a451e51aacdc",
   "metadata": {},
   "source": [
    "## 5. (6pt) Calculate the accuracy of the predicted output labels, compared with the true output labels. You can calculate it using your own code or using sklearn.metrics package. How to interpret the accuracy? Do you think the accuracy is high enough, such that you are comfortable deploying this model in real world to predict heart attack? (Hint: you should get about 80% accuracy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c9ba0c5-6916-4058-850e-c8da20c25790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.04918032786885"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_y_pred_labels == test_y)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79883f3d-adb0-492e-b266-9e1a526442ee",
   "metadata": {},
   "source": [
    "The accuracy means the percentage of predictions that are correct. In this case, it means that around 80% of our predictions perfectly predicted the outcome. Because this scenario involves someone's life, I would like the accuracy to be higher, maybe around 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd281fdc-51f3-4b0d-b52b-f7c79528d413",
   "metadata": {},
   "source": [
    "## 6. (6pt) Create a confusion matrix on the training data. Calculate accuracy, precision, and recall based on the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5495c5e-5ca7-4776-9e6c-3e6415df1510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103,  35],\n",
       "       [ 22, 143]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "m1 = LogisticRegression().fit(x, y)\n",
    "yhat = m1.predict(x)\n",
    "\n",
    "cm = confusion_matrix(y, yhat)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a94c2fbc-9218-47a3-864f-23946d0db06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8118811881188119"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == yhat) #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a38b3483-e77f-459f-a5ff-fe51d70422b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8033707865168539"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y, yhat) #precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ce1f7be-a3d4-443a-9d6b-27535b856f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y, yhat) #recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4578d51-d716-45be-9bce-2577e9fdcf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177574e5-cc7e-431c-be3a-43bd1d0025a7",
   "metadata": {},
   "source": [
    "# 2. Predict AirBnB Price (40pt)\n",
    "## 1. (5pt) Replicate the model from PS06 question 2.7. Copy paste of your old code is OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b8aabce-b024-4f6b-9296-ffb11ffa2bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171/722983309.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  airbnb['price'] = airbnb['price'].str.replace('$', '')\n"
     ]
    }
   ],
   "source": [
    "airbnb = pd.read_csv('../data/airbnb-beijing-listings.csv.bz2', usecols=['price', 'bedrooms', 'accommodates', 'bathrooms', 'room_type'])\n",
    "airbnb['price'] = airbnb['price'].str.replace('$', '')\n",
    "airbnb['price'] = airbnb['price'].str.replace(',', '')\n",
    "airbnb.price = pd.to_numeric(airbnb.price, errors='coerce')\n",
    "airbnb = airbnb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add83f65-f5d8-4f4f-a0fb-f3c0920f94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['bedrooms'].astype(float)\n",
    "airbnb['bedrooms'] = np.where(airbnb.bedrooms >= 4, '4+', airbnb.bedrooms).astype(str)\n",
    "airbnb['bedrooms'] = np.where(airbnb.bedrooms == 1, '1', airbnb.bedrooms).astype(str)\n",
    "airbnb['bedrooms'] = np.where(airbnb.bedrooms == 2, '2', airbnb.bedrooms).astype(str)\n",
    "airbnb['bedrooms'] = np.where(airbnb.bedrooms == 3, '3', airbnb.bedrooms).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71725e47-8fed-4574-8d13-795a510d6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['log_price'] = np.log(airbnb.price + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6c31cb8-cd6b-4214-90c7-07475116737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb['accommodates'].astype(float)\n",
    "airbnb['accommodates'] = np.where(airbnb.accommodates >= 4, '4 and more', airbnb.accommodates).astype(str)\n",
    "airbnb['accommodates'] = np.where(airbnb.accommodates == 1, '1', airbnb.accommodates).astype(str)\n",
    "airbnb['accommodates'] = np.where(airbnb.accommodates == 2, '2', airbnb.accommodates).astype(str)\n",
    "airbnb['accommodates'] = np.where(airbnb.accommodates == 3, '3', airbnb.accommodates).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd32836b-7225-4266-a23a-2c2f339453bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb.bathrooms = airbnb['bathrooms'].astype(float)\n",
    "airbnb['rounded_bath'] = np.ceil(airbnb.bathrooms) #rounded all the .5 bathrooms up\n",
    "airbnb['bathrooms_str'] = np.where(airbnb.rounded_bath == 0, '0', airbnb.rounded_bath).astype(str)\n",
    "airbnb['bathrooms_str'] = np.where(airbnb.rounded_bath == 1, '1', airbnb.rounded_bath).astype(str)\n",
    "airbnb['bathrooms_str'] = np.where(airbnb.rounded_bath == 2, '2', airbnb.rounded_bath).astype(str)\n",
    "airbnb['bathrooms_str'] = np.where(airbnb.rounded_bath >= 3, '3 and more', airbnb.rounded_bath).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6737bbf-37fd-4c3c-aa7a-7988de0e18f3",
   "metadata": {},
   "source": [
    "## 2. (10pt) Now use the model above to predict (log) price for each listing in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e020e8f4-bd86-4f25-9a95-cc8675ab6176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34094    5.646500\n",
       "35912    5.646500\n",
       "1885     6.002294\n",
       "38531    5.968708\n",
       "25300    6.716133\n",
       "           ...   \n",
       "8129     5.646500\n",
       "34326    6.280439\n",
       "10132    5.968708\n",
       "23761    6.716133\n",
       "31511    5.646500\n",
       "Length: 7739, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = airbnb.drop(columns=['price', 'log_price', 'rounded_bath', 'bathrooms'])\n",
    "y = airbnb.log_price\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(x,y, test_size=0.2)\n",
    "\n",
    "m = smf.ols('log_price ~ bedrooms + accommodates + bathrooms_str + room_type', data=airbnb).fit()\n",
    "predictions = m.predict(test_X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23132f96-2407-4c26-bb49-b348ac671cca",
   "metadata": {},
   "source": [
    "## 3. (10pt) Compute root-mean-squared-error (RMSE) of this prediction. RMSE is explained in lecture notes, 4.1.5 “Model evaluation: MSE, RMSE, R2”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57e3a0d9-1486-4ee9-b25a-53d3cd88570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.601819061529174"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(test_y, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1e2b1-ebcf-4a9e-93c4-ed45d6c53fa0",
   "metadata": {},
   "source": [
    "## 4. (10pt) Now use your model to predict the price for a 2-bedroom apartment that accommodates 4 (i.e. a full 2BR apartment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "791a3dab-4d6e-4ac2-b06c-8f826b9bbb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>log_price</td>    <th>  R-squared:         </th> <td>   0.453</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.453</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2669.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Mar 2022</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:02:42</td>     <th>  Log-Likelihood:    </th> <td> -36034.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 38695</td>      <th>  AIC:               </th> <td>7.209e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 38682</td>      <th>  BIC:               </th> <td>7.220e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                  <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                   <td>    5.5593</td> <td>    0.062</td> <td>   89.221</td> <td> 0.000</td> <td>    5.437</td> <td>    5.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms[T.1.0]</th>             <td>    0.0778</td> <td>    0.040</td> <td>    1.935</td> <td> 0.053</td> <td>   -0.001</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms[T.2.0]</th>             <td>    0.2104</td> <td>    0.041</td> <td>    5.107</td> <td> 0.000</td> <td>    0.130</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms[T.3.0]</th>             <td>    0.5135</td> <td>    0.043</td> <td>   12.062</td> <td> 0.000</td> <td>    0.430</td> <td>    0.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms[T.4+]</th>              <td>    0.8933</td> <td>    0.044</td> <td>   20.263</td> <td> 0.000</td> <td>    0.807</td> <td>    0.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accommodates[T.2]</th>           <td>    0.3304</td> <td>    0.014</td> <td>   24.339</td> <td> 0.000</td> <td>    0.304</td> <td>    0.357</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accommodates[T.3]</th>           <td>    0.3942</td> <td>    0.017</td> <td>   23.512</td> <td> 0.000</td> <td>    0.361</td> <td>    0.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accommodates[T.4 and more]</th>  <td>    0.6085</td> <td>    0.016</td> <td>   39.040</td> <td> 0.000</td> <td>    0.578</td> <td>    0.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms_str[T.1.0]</th>        <td>    0.0013</td> <td>    0.047</td> <td>    0.028</td> <td> 0.978</td> <td>   -0.091</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms_str[T.2.0]</th>        <td>    0.0349</td> <td>    0.047</td> <td>    0.735</td> <td> 0.462</td> <td>   -0.058</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms_str[T.3 and more]</th> <td>    0.5902</td> <td>    0.050</td> <td>   11.858</td> <td> 0.000</td> <td>    0.493</td> <td>    0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type[T.Private room]</th>   <td>   -0.3222</td> <td>    0.007</td> <td>  -43.246</td> <td> 0.000</td> <td>   -0.337</td> <td>   -0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>room_type[T.Shared room]</th>    <td>   -0.9463</td> <td>    0.017</td> <td>  -55.789</td> <td> 0.000</td> <td>   -0.980</td> <td>   -0.913</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>8589.601</td> <th>  Durbin-Watson:     </th> <td>   1.781</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>77599.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.814</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 9.744</td>  <th>  Cond. No.          </th> <td>    52.9</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              log_price   R-squared:                       0.453\n",
       "Model:                            OLS   Adj. R-squared:                  0.453\n",
       "Method:                 Least Squares   F-statistic:                     2669.\n",
       "Date:                Fri, 04 Mar 2022   Prob (F-statistic):               0.00\n",
       "Time:                        01:02:42   Log-Likelihood:                -36034.\n",
       "No. Observations:               38695   AIC:                         7.209e+04\n",
       "Df Residuals:                   38682   BIC:                         7.220e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================================\n",
       "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------\n",
       "Intercept                       5.5593      0.062     89.221      0.000       5.437       5.681\n",
       "bedrooms[T.1.0]                 0.0778      0.040      1.935      0.053      -0.001       0.157\n",
       "bedrooms[T.2.0]                 0.2104      0.041      5.107      0.000       0.130       0.291\n",
       "bedrooms[T.3.0]                 0.5135      0.043     12.062      0.000       0.430       0.597\n",
       "bedrooms[T.4+]                  0.8933      0.044     20.263      0.000       0.807       0.980\n",
       "accommodates[T.2]               0.3304      0.014     24.339      0.000       0.304       0.357\n",
       "accommodates[T.3]               0.3942      0.017     23.512      0.000       0.361       0.427\n",
       "accommodates[T.4 and more]      0.6085      0.016     39.040      0.000       0.578       0.639\n",
       "bathrooms_str[T.1.0]            0.0013      0.047      0.028      0.978      -0.091       0.094\n",
       "bathrooms_str[T.2.0]            0.0349      0.047      0.735      0.462      -0.058       0.128\n",
       "bathrooms_str[T.3 and more]     0.5902      0.050     11.858      0.000       0.493       0.688\n",
       "room_type[T.Private room]      -0.3222      0.007    -43.246      0.000      -0.337      -0.308\n",
       "room_type[T.Shared room]       -0.9463      0.017    -55.789      0.000      -0.980      -0.913\n",
       "==============================================================================\n",
       "Omnibus:                     8589.601   Durbin-Watson:                   1.781\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            77599.711\n",
       "Skew:                           0.814   Prob(JB):                         0.00\n",
       "Kurtosis:                       9.744   Cond. No.                         52.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45cd33d9-1ace-4bb2-a974-56e20dd406a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3782000000000005"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.5593 + 0.2104*1 + 0.6085"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b567e-34df-4dd3-8fdc-93e3dbf037c3",
   "metadata": {},
   "source": [
    "## 5. (5pt) Compute the average log price for all listings in this group (2BR apartment that accommodates 4). Compare the result with your prediction. How close did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d385e813-5312-411e-b525-a4eceb17764b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.343438554517532"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = airbnb[airbnb.accommodates == '4 and more']\n",
    "a = airbnb[airbnb.bedrooms == '2.0']\n",
    "np.mean(a.log_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efcfbb-3bc7-48c6-bde3-db6d1b1cf2f7",
   "metadata": {},
   "source": [
    "I got a pretty close answer to my prediction from problem 2.4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
